---
title: "p8105_hw3_sal2222"
author: "Stephen Lewandowski"
date: "October 15, 2018"
output: 
  github_document:
    toc: true
---


```{r setup, include = FALSE}

library(tidyverse)
library(readxl)
library(devtools)
library(p8105.datasets) #devtools::install_github("p8105/p8105.datasets")

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))
```

# Problem 1: BRFSS


I will load and format the Behavioral Risk Factors Surveillance System (BRFSS) for Selected Metropolitan Area Risk Trends (SMART) data from the p8105.datasets package.

```{r load and clean BRFSS}

data("brfss_smart2010")

brfss <- brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>%
  select(-c(class, topic, question, sample_size, confidence_limit_low:geo_location)) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  separate(county, into = c("remove", "county"), sep = "- ") %>%
  select(year, state, county, poor, fair, good, very_good, excellent)
  
brfss
   
```


I will answer questions using this BRFSS dataset.

*In 2002, which states were observed at 7 locations?*

```{r brfss states with 7 locations}

brfss %>% 
  filter(year == 2002) %>% 
  group_by(state) %>% 
  summarise(number = n()) %>% 
  filter(number == 7)

```

In 2002, 7 locations were observed in **Connecticut, Florida, and North Carolina**.    



*Make a “spaghetti plot” that shows the number of observations in each state from 2002 to 2010.*

```{r spaghetti plot}
brfss %>% 
  group_by(state, year) %>% 
  summarise(number = n()) %>% 
  ggplot(aes(x = year, y = number)) +
    geom_line(aes(color = state, alpha = 0.5)) +
    geom_smooth(method = "loess", se = TRUE) + 
    labs(
      title = "Locations observed by state, 2002-2010",
      x = "Year",
      y = "Number of observations",
      caption = "Data from BRFSS SMART 2010"
    ) +
    viridis::scale_color_viridis(
      name = "State", 
    discrete = TRUE
    ) +
    theme(legend.position = "none")
```



This plot is useful for showing the general trend of locations by state from 2002 to 2010. However, it is very difficult to identify individual states, and a legend for all of the states occupies too much space, if included. A loess smoothed conditional mean curve shows a very gradual increase in number of locations observed by state over this time period.  



*Make a table showing, for the years 2002, 2006, and 2010, the mean and standard deviation of the proportion of “Excellent” responses across locations in NY State.*

```{r brfss table NY state, warning = FALSE}

brfss %>% 
  filter(year == 2002 | 2006 | 2010) %>% 
  filter(state == "NY") %>% 
  group_by(year) %>%
  summarise(mean_excellent = mean(excellent),
            sd_excellent = sd(excellent)) %>% 
  knitr::kable(digits = 1, caption = "Proportion of “Excellent” responses across locations in NY State")
  
```


The table above shows the mean and standard deviation of the proportion of “Excellent” responses across locations in NY State. Nothing in particular stands out from the results. The highest proportion of "Excellent" responses occurred in 2002 (24.0%) and the lowest occurred in 2007 (21.1%).   


*For each year and state, compute the average proportion in each response category (taking the average across locations in a state). Make a five-panel plot that shows, for each response category separately, the distribution of these state-level averages over time*

```{r BFRSS five panel plot, warning = FALSE}

brfss %>% 
  select(-county) %>% 
  group_by(year, state) %>% 
  summarise_all(funs(mean = "mean")) %>% 
  gather(key = rating, value = mean_proportion, poor_mean:excellent_mean) %>%
  mutate(rating = 
      factor(rating, c("poor_mean", "fair_mean", "good_mean", "very_good_mean", "excellent_mean"))) %>% 
  ggplot(aes(x = year, y = mean_proportion)) +
    geom_line(aes(color = state, alpha = 0.5)) +
    geom_smooth(method = "loess", se = TRUE) + 
    facet_grid(~rating) + 
    labs(
      title = "Locations observed by state, 2002-2010",
      x = "Year",
      y = "Number of observations",
      caption = "Data from BRFSS SMART 2010"
    ) +
    viridis::scale_color_viridis(
      name = "State", 
    discrete = TRUE
    ) +
    theme(legend.position = "none", 
          axis.text.x = element_text(size = 5))

```



The five-panel plot above displays the average proportion in each response category in the BRFSS "Overall Health" topic, averaged across county-level regions in each state, with a loess smoothed conditional mean curve and 95% confidence level. We see the distribution of state-level averages over time from 2002 to 2008. "Very good" makes up the highest proportion of responses, followed by "good", "excellent", "fair", and lastly "poor". For the most part, the trend of responses remained consistent over time. The proportion of "very good" responses increases slightly, and "excellent" responses decrease slightly over this period.    




#Problem 2: Instacart

```{r load Instacart data}

data("instacart")
instacart


```


This Instacart Online Grocery Shopping 2017 dataset comes from an anonymized dataset with over 3 million online grocery orders from more than 200,000 Instacart users. This version of the data contains `r nrow(instacart)` observations of products in the orders. There are `r ncol(instacart)` variables in this dataset that describe order, product, and customer identifiers, the order in which the item was added to a user's cart, whether the product had been previously ordered by the user, the order sequence from the user, the hour and day of the week the order was placed, day since prior order, as well as product name, aisle, and department information. Our data contains `r instacart %>% summarize(n_distinct = n_distinct(order_id))` unique orders for `r instacart %>% summarize(n_distinct = n_distinct(product_id))` unique products. The average number of items in an order was `r instacart %>% group_by(order_id) %>% summarize(n = n()) %>% summarize(mean = mean(n))`.   


*How many aisles are there, and which aisles are the most items ordered from?*

```{r instacart aisles}
instacart %>% 
  summarize(n_distinct = n_distinct(aisle_id))

instacart %>%
  group_by(aisle) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n))

```

There are **134** aisles in the database. The most items are ordered from **Fresh Vegetables (150,609), Fresh Fruits (150,773), and Package Vegetables and Fruits (78,493)**. 
Users seem to order healthy foods from this service.


*Make a plot that shows the number of items ordered in each aisle. Order aisles sensibly, and organize your plot so others can read it.*


```{r plot items in aisles ordered by aisle ID}

instacart %>%
 group_by(aisle_id) %>% 
  summarize(n = n()) %>%
  ggplot(aes(x = aisle_id, y = n)) +
    geom_bar(stat = "identity") +
        labs(
     title = "Number of items ordered in each Instacart aisle",
      x = "Aisle ID",
      y = "Number of items ordered",
      caption = "Data from Instacart"
    )  +
    scale_x_continuous(breaks = c(0, 20, 40, 60, 80, 100, 120, 140)) +
    scale_y_continuous(labels = scales::comma)

```

The plot above shows the number of items ordered in each aisle with the x-axis arranged sequentially by the aisle identification number. This display may be useful to get an idea of layout efficiency. We see that popular aisles are fairly evenly dispersed throughout the span of aisles. 


```{r plot items in aisles ordered by number of items}

instacart %>%
 group_by(aisle_id) %>% 
  summarize(n = n()) %>%
  ggplot(aes(x = reorder(aisle_id, -n), y = n)) +
    geom_bar(stat = "identity") +
    labs(
     title = "Number of items ordered in each Instacart aisle",
      x = "Aisle ID",
      y = "Number of items ordered",
      caption = "Data from Instacart"
    ) +
    theme(axis.text.x = element_text(angle = 90, size = 4)) +
     scale_y_continuous(labels = scales::comma)
```

The plot above shows the number of items ordered in each aisle with the x-axis arranged from highest to lowest. This display is useful to visualize differences between the items ordered per aisle. However, because the 134 aisles are out of order, it is not easy to locate a specific aisle of interest. 


*Make a table showing the most popular item in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”*

```{r popular item table}
instacart %>%
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  summarize(most_popular_item = first(product_name)) %>% 
  knitr::kable()
```

The table above shows the most popular item in three selected aisles. The items (corn starch, dog biscuits, salad) make sense for their respective aisles.


*Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).*

```{r time of order table, warning = FALSE}
instacart %>%
  filter(product_name == c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  mutate(order_dow = recode_factor(order_dow,
       "0" = "Sunday",
       "1" = "Monday",
       "2" = "Tuesday",
       "3" = "Wednesday",
       "4" = "Thursday",
       "5" = "Friday",
       "6" = "Saturday")) %>% 
  group_by(product_name, order_dow) %>%
  summarize(mean_hour_of_day = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour_of_day) %>% 
  knitr::kable(digits = 2)

```

The table above displays the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream were ordered on each day of the week. The mean hour values are based on a 24 hour clock, and represent fraction of an hour, rather than hours and minutes. From the `order_dow` variable, day `0` was assumed to represent Sunday. We see that every day except for Friday, the ice cream is ordered later in the day than the apples. Lunchtime and late afternoon are the most popular order times, except for the Friday morning coffee ice cream.     






#Problem 3: NY NOAA